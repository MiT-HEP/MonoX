. Compute the luminosity (uses source simpletree)
  misc/lumilist.py <samples> [--mask <lumimask>] --save --save-plain

. Update the number of events for the data samples (technically not necessary)
  datasets.py recalculate <samples> --save

. Compute the data pileup distribution and construct the PU weights
  pileupCalc.py -i data/lumis_plain.txt --inputLumiJSON /afs/cern.ch/cms/CAF/CMSCOMM/COMM_DQM/certification/Collisions16/13TeV/PileUp/pileup_latest.txt --calcMode true --minBiasXsec 71300 --maxPileupBin 80 dataPileup.root
  misc/puweight.py dataPileup.root 2016_25ns_SpringMC_PUScenarioV1_PoissonOOTPU $PWD/data/pileup.root

. Run the trigger efficiency measurement and update the L1 fit parameters in selectors.py
  trigger/eff.py
  (sph, sel, smu; tpeg, tpegLowPt, tpmgLowPt)

. Run the photon ID and lepton veto efficiency measurements. Propagate the SF and uncertainty to selectors.py
  veto_eff/compute.py
  (smu, zllg, tt, ww, wz, zz; tpmmg)

. At this point, all the weights for MC samples have been updated and you can reskim all the MC samples (but don't yet)

. Run the e->photon fake rate study. Copy the output of compute to data/efake_data_pt.root
  tp/efake_fit.py data highpt
  condor-run $PWD/tp/efake_fit.py -e "data pt 1000 (ee|eg) pt_X_Y" -j $(seq 1 200)
  tp/efake_compute.py data highpt # make sure toyUncert is set to True
  (sph; tpeg, tpmg)

. Run the photon purity measurement.
  purity/calcPurity.py barrel medium-pixel <pt> 0to60 Ashim_ZG_CWIso
  purity/plotPurity.py
  (sph, gj; emjet), (sph, dy-50-*; tpeg)

(.) Run the photon purity measurement for no-ICH case (medium-pixel-noICH). Generate the vertex scores templates.
  chiso/scores.py
  (sph; dimuAllPhoton, dielAllPhoton, monomuAllPhoton)

(.) Measure the random-cone isolation probability

. Run the hadron transfer factor measurement.
  hadron_fake/hadronTFactor.py
  (sph; emjet)

. Run method 1 and 2 of the gamma + jets background estimation.

. Run the sph skims

. Run the halo phi fit (for display)
  halo/phidistributions.py for plots
  halo/phifit.py for actual fits

. Run method 3 of gamma + jets background estimation.
  gjets/smearfit.py

. Run all MC monoph skims (if PU reweighting changed)

. Make plots and data card inputs
  main/plot.py monoph
  main/plot.py -p met -o monoph_met.root --allsignal

. Make data cards
  main/datacard.py {model} monoph_met.root
  for model in ; do python datacard.py $model monoph_met.root; done

. Run combine
  scratch/runCombine.sh {point}
  for f in /scratch5/ballen/hist/monophoton/datacards/*; do echo $f >> cards.txt; done
  ~/bin/condor-run scratch/runCombine.sh -a cards.txt

. Fix scaled samples
  scratch/fixLimit.py

. Plot limits
  scratch/plotlimit.py
