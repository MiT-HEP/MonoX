[Installation]

 The fit routines in this directory may use KeysShape, which is an
 original implementation of 1D Gaussian kernel estimator
 (hep-ex/0011057). It is functionally identical to RooKeysPdf, but
 uses multiple threads (configurable) to speed the PDF construction
 up. The source code is available at
  https://github.com/yiiyama/RooFit.git
 You need to check it out and build the library:
  cd RooFit
  make
 then set roofitDictDir in efake_conf.py to the directory where
 libCommonRooFit.so is.

[efake]
 
 The electron->photon fake rate measurement proceeds in three steps:

 1. ssw2.py
 2. fit (efake_fit.py)
 3. evaluate uncertianties (efake_tpsyst.py)
 3. compute (efake_compute.py)

 1. Skim
 sww2.py produces files sample_tpeg.root, sample_tpmg.root, and
 sample_mmg.root for use by efake_fit.py.

 2. Fit
 Templates for the fits are made using efake_template.py. The MC fits must be
 performed before making the data templates since some of the background templates
 rely on the MC results.
 Fits with the nominal and alternative models are performed in efake_fit.py:

  efake_template.py mc (binning)
  efake_fit.py mc (binning)
  efake_template.py data (binning)
  efake_fit.py data (binning)

 runs a fit for the Z yield estimates. Fits with the nominal, altsig, and altbkg
 models are run on each bin of the (binning). Results are saved into a RooDataSet
 imported into RooWorkspace "work".

 3. Uncertainty
 Then efake_tpsyst.py throws toys to evaluate statistical and systematic uncertainties.

  efake_tpsyst.py (data|mc) (binning) (bin name) (ee|eg) (nominal|altsig|altbkg) (N) (random seed)

 runs N toy fits for (ee|eg)_(bin name) with the specified random seed. If the 4th argument
 is "nominal", toy data generated from the nominal model is refit with the same model,
 and repeating the fit results in a distribution of nsignal values from which we can estimate
 the statistical uncertainty of the fit. If the 4th argument is altsi or altbkg, the toy
 data is generated from alternative models with best-fit parameters (determined in efake_fit).
 With condor-run

  binning=ptalt
  seed=1001
  for bin in $(python efake_conf.py $binning)
  do
    for conf in ee eg
    do
      for type in nominal altsig altbkg
      do
        while true
        do
          echo $bin $conf $type 200 $seed >> syst_args.txt
          seed=$(($seed+1))
          [ $(($seed%2)) -eq 0 ] && break
        done
      done
    done
  done
  ~/bin/condor-run efake_tpsyst.py -e "data $binning" -a syst_args.txt
  ~/bin/condor-run efake_tpsyst.py -e "data $binning" -a syst_args.txt

  You can also use makeSystArgs.sh to generate the text file with all the job parameters.

 The output of toy generation should be combined (you will need to switch to the output directory first):
  hadd tpsyst_data_(binning).root (binning)/tpsyst_data_*.root
  hadd tpsyst_mc_(binning).root (binning)/tpsyst_mc_*.root

 4. Finalize
  efake_compute.py takes this ROOT file as an input and makes the fake rate graph.
  efake_compute.py (data|mc) (binning)

 5. Scale Factors
  Repeat steps 2), 3), and 4) but with 'eff' as the product instead of of 'frate' (you can set this in efake_conf.py).
  All four confs (pass, fail, ee, eg) can be combined into a single tpsyst_*.root file.
  Step 4) will produce files with the efficiencies in MC and data.
  Finally run sf_compute.py (binning) to produce the final set of scale factors.
  
 